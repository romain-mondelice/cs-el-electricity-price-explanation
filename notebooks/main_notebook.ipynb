{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRT ENS Challenge Data 2023 - Benchmark\n",
    "\n",
    "Version 1 - Boosting, Feature engeneering & XGBoost \n",
    "\n",
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monde\\AppData\\Local\\Temp\\ipykernel_17364\\506212645.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "- `X_train` et `X_test` ont  $35$ colonnes qui représentent les même variables explicatives mais sur des périodes de temps différentes. \n",
    "\n",
    "- `X_train` et `Y_train` partagent la même colonne `ID` - chaque ligne a un ID unique associé à un jour et à un pays. \n",
    "\n",
    "- La variable cible `TARGET` de `Y_train` correspond à la variation de prix journalière des futures sur l'électricité (maturité 24h).\n",
    "\n",
    "- **On notera que certaines colonnes ont des valeurs manquantes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After downloading the X_train/X_test/Y_train .csv files in your working directory:\n",
    "\n",
    "X_train = pd.read_csv('../data/raw/X_train.csv')\n",
    "Y_train = pd.read_csv('../data/raw/y_train.csv')\n",
    "X_test = pd.read_csv('../data/raw/X_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DAY_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_CONSUMPTION</th>\n",
       "      <th>DE_FR_EXCHANGE</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_EXPORT</th>\n",
       "      <th>FR_NET_EXPORT</th>\n",
       "      <th>DE_NET_IMPORT</th>\n",
       "      <th>...</th>\n",
       "      <th>FR_RESIDUAL_LOAD</th>\n",
       "      <th>DE_RAIN</th>\n",
       "      <th>FR_RAIN</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "      <th>DE_TEMP</th>\n",
       "      <th>FR_TEMP</th>\n",
       "      <th>GAS_RET</th>\n",
       "      <th>COAL_RET</th>\n",
       "      <th>CARBON_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>206</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.210099</td>\n",
       "      <td>-0.427458</td>\n",
       "      <td>-0.606523</td>\n",
       "      <td>0.606523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444661</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.556356</td>\n",
       "      <td>-0.790823</td>\n",
       "      <td>-0.283160</td>\n",
       "      <td>-1.069070</td>\n",
       "      <td>-0.063404</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>0.124552</td>\n",
       "      <td>-0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049</td>\n",
       "      <td>501</td>\n",
       "      <td>FR</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>-1.003452</td>\n",
       "      <td>-0.022063</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>-0.573520</td>\n",
       "      <td>-1.130838</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183194</td>\n",
       "      <td>-1.240300</td>\n",
       "      <td>-0.770457</td>\n",
       "      <td>1.522331</td>\n",
       "      <td>0.828412</td>\n",
       "      <td>0.437419</td>\n",
       "      <td>1.831241</td>\n",
       "      <td>-0.659091</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>-0.490365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>687</td>\n",
       "      <td>FR</td>\n",
       "      <td>1.395035</td>\n",
       "      <td>1.978665</td>\n",
       "      <td>1.021305</td>\n",
       "      <td>-1.021305</td>\n",
       "      <td>-0.622021</td>\n",
       "      <td>-1.682587</td>\n",
       "      <td>0.622021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947273</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>-0.313338</td>\n",
       "      <td>0.431134</td>\n",
       "      <td>0.487608</td>\n",
       "      <td>0.684884</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.535974</td>\n",
       "      <td>0.743338</td>\n",
       "      <td>0.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>720</td>\n",
       "      <td>DE</td>\n",
       "      <td>-0.983324</td>\n",
       "      <td>-0.849198</td>\n",
       "      <td>-0.839586</td>\n",
       "      <td>0.839586</td>\n",
       "      <td>-0.270870</td>\n",
       "      <td>0.563230</td>\n",
       "      <td>0.270870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976974</td>\n",
       "      <td>-1.114838</td>\n",
       "      <td>-0.507570</td>\n",
       "      <td>-0.499409</td>\n",
       "      <td>-0.236249</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>-0.417514</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>1.073948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>818</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>-0.617038</td>\n",
       "      <td>-0.924990</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526267</td>\n",
       "      <td>-0.541465</td>\n",
       "      <td>-0.424550</td>\n",
       "      <td>-1.088158</td>\n",
       "      <td>-1.011560</td>\n",
       "      <td>0.614338</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>1.526606</td>\n",
       "      <td>2.614378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  DE_FR_EXCHANGE  \\\n",
       "0  1054     206      FR        0.210099       -0.427458       -0.606523   \n",
       "1  2049     501      FR       -0.022399       -1.003452       -0.022063   \n",
       "2  1924     687      FR        1.395035        1.978665        1.021305   \n",
       "3   297     720      DE       -0.983324       -0.849198       -0.839586   \n",
       "4  1101     818      FR        0.143807       -0.617038       -0.924990   \n",
       "\n",
       "   FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  DE_NET_IMPORT  ...  \\\n",
       "0        0.606523            NaN       0.692860            NaN  ...   \n",
       "1        0.022063      -0.573520      -1.130838       0.573520  ...   \n",
       "2       -1.021305      -0.622021      -1.682587       0.622021  ...   \n",
       "3        0.839586      -0.270870       0.563230       0.270870  ...   \n",
       "4        0.924990            NaN       0.990324            NaN  ...   \n",
       "\n",
       "   FR_RESIDUAL_LOAD   DE_RAIN   FR_RAIN   DE_WIND   FR_WIND   DE_TEMP  \\\n",
       "0         -0.444661 -0.172680 -0.556356 -0.790823 -0.283160 -1.069070   \n",
       "1         -1.183194 -1.240300 -0.770457  1.522331  0.828412  0.437419   \n",
       "2          1.947273 -0.480700 -0.313338  0.431134  0.487608  0.684884   \n",
       "3         -0.976974 -1.114838 -0.507570 -0.499409 -0.236249  0.350938   \n",
       "4         -0.526267 -0.541465 -0.424550 -1.088158 -1.011560  0.614338   \n",
       "\n",
       "    FR_TEMP   GAS_RET  COAL_RET  CARBON_RET  \n",
       "0 -0.063404  0.339041  0.124552   -0.002445  \n",
       "1  1.831241 -0.659091  0.047114   -0.490365  \n",
       "2  0.114836  0.535974  0.743338    0.204952  \n",
       "3 -0.417514  0.911652 -0.296168    1.073948  \n",
       "4  0.729495  0.245109  1.526606    2.614378  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>0.028313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049</td>\n",
       "      <td>-0.112516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1924</td>\n",
       "      <td>-0.180840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297</td>\n",
       "      <td>-0.260356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>-0.071733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID    TARGET\n",
       "0  1054  0.028313\n",
       "1  2049 -0.112516\n",
       "2  1924 -0.180840\n",
       "3   297 -0.260356\n",
       "4  1101 -0.071733"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"TARGET\"] = Y_train[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "The main goal here is to reconstruct some of the lost time dimension to create stationary features.\n",
    "\n",
    "In general we had added statistics, technical indicators, seasonality, clusters and bag of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(y):\n",
    "    return np.polyfit(range(len(y)), y, 1)[0] if len(y) > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_statistics(df, variables, windows, countries=['DE_', 'FR_']):\n",
    "    # Define a slope calculation function\n",
    "    def slope(y):\n",
    "        return np.polyfit(range(len(y)), y, 1)[0] if len(y) > 0 else np.nan\n",
    "\n",
    "    # Calculate rolling statistics for each variable and window\n",
    "    for var in variables:\n",
    "        for window in windows:\n",
    "            for country in countries:\n",
    "                df[f'{country}{var}_MEAN_{window}D'] = df[f'{country}{var}'].rolling(window=window).mean()\n",
    "                df[f'{country}{var}_STD_{window}D'] = df[f'{country}{var}'].rolling(window=window).std()\n",
    "                df[f'{country}{var}_MEDIAN_{window}D'] = df[f'{country}{var}'].rolling(window=window).median()\n",
    "                df[f'{country}{var}_MIN_{window}D'] = df[f'{country}{var}'].rolling(window=window).min()\n",
    "                df[f'{country}{var}_MAX_{window}D'] = df[f'{country}{var}'].rolling(window=window).max()\n",
    "                # Apply the slope function to the rolling window\n",
    "                df[f'{country}{var}_SLOPE_{window}D'] = df[f'{country}{var}'].rolling(window=window).apply(slope, raw=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_seasonality_features(df):\n",
    "    days_in_year = 365.25\n",
    "    df['SIN_YEAR'] = np.sin(2 * np.pi * df['DAY_ID'] / days_in_year)\n",
    "    df['COS_YEAR'] = np.cos(2 * np.pi * df['DAY_ID'] / days_in_year)\n",
    "    \n",
    "    days_in_week = 7\n",
    "    df['SIN_WEEK'] = np.sin(2 * np.pi * df['DAY_ID'] / days_in_week)\n",
    "    df['COS_WEEK'] = np.cos(2 * np.pi * df['DAY_ID'] / days_in_week)\n",
    "\n",
    "    df['SEASON'] = pd.cut(df['DAY_ID'] % 365, bins=[0, 79, 172, 264, 365], labels=[0, 1, 2, 3], right=False).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_energy_source_ratios_and_effects(df):\n",
    "    for country in ['DE_', 'FR_']:\n",
    "        for energy_source in ['GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'SOLAR', 'WINDPOW']:\n",
    "            total_energy = df[f'{country}GAS'] + df[f'{country}COAL'] + df[f'{country}HYDRO'] + \\\n",
    "                           df[f'{country}NUCLEAR'] + df[f'{country}SOLAR'] + df[f'{country}WINDPOW']\n",
    "            df[f'{country}{energy_source}_RATIO'] = df[f'{country}{energy_source}'] / total_energy\n",
    "\n",
    "        df[f'{country}WIND_SOLAR'] = df[f'{country}WINDPOW'] + df[f'{country}SOLAR']\n",
    "        df[f'{country}TEMP_EFFECT'] = df[f'{country}TEMP'] * df[f'{country}CONSUMPTION']\n",
    "        df[f'{country}WIND_EFFECT'] = df[f'{country}WIND'] * df[f'{country}WINDPOW']\n",
    "        df[f'{country}SOLAR_EFFECT'] = (df[f'{country}SOLAR'] / df[f'{country}TEMP']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_market_features(df):\n",
    "    for commodity in ['GAS_RET', 'COAL_RET', 'CARBON_RET']:\n",
    "        df[f'{commodity}_VOLATILITY_7D'] = df[commodity].rolling(window=7).std()\n",
    "        df[f'{commodity}_VOLATILITY_30D'] = df[commodity].rolling(window=30).std()\n",
    "        df[f'{commodity}_EMA_30D'] = df[commodity].ewm(span=30, adjust=False).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_features(df):\n",
    "    # Temporal window and variables for rolling statistics\n",
    "    windows = [7, 30]\n",
    "    variables = ['CONSUMPTION', 'GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'SOLAR', 'WINDPOW', 'TEMP', 'RAIN', 'WIND']\n",
    "\n",
    "    # Calculate rolling statistics and other features\n",
    "    df = add_rolling_statistics(df, variables, windows)\n",
    "\n",
    "    # Seasonality Features\n",
    "    df = add_seasonality_features(df)\n",
    "\n",
    "    # Energy Source Ratios and Effects\n",
    "    df = add_energy_source_ratios_and_effects(df)\n",
    "\n",
    "    # Market Volatility and Moving Averages\n",
    "    df = add_market_features(df)\n",
    "\n",
    "    # Ensure all missing data are filled if any new were created\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def feature_engineering(X):\n",
    "    # Copy the original dataframe to avoid modifying it directly\n",
    "    df = X.copy()\n",
    "    \n",
    "    # Define the country codes\n",
    "    country_codes = {'DE': 0, 'FR': 1}\n",
    "    \n",
    "    # Map country codes to numerical values\n",
    "    df['COUNTRY'] = df['COUNTRY'].map(country_codes)\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[df.columns] = imputer.fit_transform(df)\n",
    "\n",
    "    df = add_custom_features(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Apply the feature engineering to the df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_based_on_correlation(dataframe, target_column, multicollinear_threshold=0.7, correlation_threshold=0.05):\n",
    "    # Calculate the Spearman correlation matrix\n",
    "    corr_matrix = dataframe.corr(method='spearman')\n",
    "    \n",
    "    # Identify features that are highly correlated with each other\n",
    "    # (excluding the target variable correlation)\n",
    "    high_corr_var = np.where(corr_matrix > multicollinear_threshold)\n",
    "    high_corr_var = [(corr_matrix.index[x], corr_matrix.columns[y]) \n",
    "                     for x, y in zip(*high_corr_var) \n",
    "                     if x != y and x < y]\n",
    "    \n",
    "    # Extract the names of columns to drop based on multicollinearity\n",
    "    multicollinear_features = set([item for sublist in high_corr_var for item in sublist])\n",
    "    \n",
    "    # Identify features that have a low correlation with the target variable\n",
    "    low_corr_with_target = corr_matrix[target_column][abs(corr_matrix[target_column]) < correlation_threshold].index.tolist()\n",
    "    \n",
    "    # Combine features to drop due to multicollinearity and low correlation with target\n",
    "    features_to_drop = multicollinear_features.union(low_corr_with_target)\n",
    "    \n",
    "    # Determine the final list of features to keep\n",
    "    features_to_keep = [feature for feature in dataframe.columns if feature not in features_to_drop and feature != target_column]\n",
    "    \n",
    "    return features_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for df: 31\n"
     ]
    }
   ],
   "source": [
    "def select_top_features(features, max_features):\n",
    "    # Sélectionnez les max_features les plus importants si le nombre de caractéristiques est plus grand que max_features\n",
    "    if len(features) > max_features:\n",
    "        return features[:max_features]\n",
    "    else:\n",
    "        return features\n",
    "\n",
    "selected_features = []\n",
    "\n",
    "# Supposons que select_features_based_on_correlation renvoie des caractéristiques triées par leur importance\n",
    "refined_features = select_features_based_on_correlation(df, 'TARGET', 0.7, 0.05)\n",
    "# Sélectionnez uniquement les 15 caractéristiques les plus importantes\n",
    "top_features = select_top_features(refined_features, 30)\n",
    "df_reduced = df[top_features + ['TARGET']]\n",
    "print(f\"Selected features for df: {len(df_reduced.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE_FR_EXCHANGE', 'FR_DE_EXCHANGE', 'DE_NET_IMPORT', 'DE_GAS', 'DE_HYDRO', 'FR_HYDRO', 'FR_WINDPOW', 'DE_RESIDUAL_LOAD', 'FR_RAIN', 'GAS_RET', 'CARBON_RET', 'DE_CONSUMPTION_MAX_7D', 'DE_GAS_MIN_30D', 'DE_COAL_SLOPE_7D', 'DE_HYDRO_MIN_7D', 'DE_HYDRO_SLOPE_7D', 'DE_HYDRO_SLOPE_30D', 'FR_HYDRO_MIN_30D', 'DE_WINDPOW_SLOPE_7D', 'FR_WINDPOW_SLOPE_7D', 'DE_WINDPOW_SLOPE_30D', 'FR_WINDPOW_SLOPE_30D', 'DE_RAIN_MIN_7D', 'DE_RAIN_SLOPE_30D', 'DE_HYDRO_RATIO', 'DE_WINDPOW_RATIO', 'DE_WIND_SOLAR', 'DE_SOLAR_EFFECT', 'FR_WIND_SOLAR', 'GAS_RET_VOLATILITY_7D']\n"
     ]
    }
   ],
   "source": [
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of GridSearch to find optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def train_and_evaluate_catboost(X, y):\n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'depth': [4, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'iterations': [200],\n",
    "        'l2_leaf_reg': [3, 7]\n",
    "    }\n",
    "\n",
    "    # Determine all combinations\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    # Set up K-Fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate over combinations\n",
    "    for params in combinations:\n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model = CatBoostRegressor(silent=True, **params)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            \n",
    "            score = spearmanr(y_test, predictions).correlation\n",
    "            scores.append(score)\n",
    "\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = params\n",
    "\n",
    "        print(f\"Params: {params}, Mean Spearman Correlation: {mean_score}\")\n",
    "\n",
    "    print(f\"Best Params: {best_params}, Best Mean Spearman Correlation: {best_score}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost model...\n",
      "Params: {'depth': 4, 'learning_rate': 0.01, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.23960420048054543\n",
      "Params: {'depth': 4, 'learning_rate': 0.01, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.24312894416374314\n",
      "Params: {'depth': 4, 'learning_rate': 0.05, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.22590630507205808\n",
      "Params: {'depth': 4, 'learning_rate': 0.05, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.23961778842645948\n",
      "Params: {'depth': 4, 'learning_rate': 0.1, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.19153053767545994\n",
      "Params: {'depth': 4, 'learning_rate': 0.1, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.19032374269872535\n",
      "Params: {'depth': 6, 'learning_rate': 0.01, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.248288950880117\n",
      "Params: {'depth': 6, 'learning_rate': 0.01, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.24612632556130487\n",
      "Params: {'depth': 6, 'learning_rate': 0.05, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.22099371333516146\n",
      "Params: {'depth': 6, 'learning_rate': 0.05, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.2360833686933474\n",
      "Params: {'depth': 6, 'learning_rate': 0.1, 'iterations': 200, 'l2_leaf_reg': 3}, Mean Spearman Correlation: 0.1837080537753574\n",
      "Params: {'depth': 6, 'learning_rate': 0.1, 'iterations': 200, 'l2_leaf_reg': 7}, Mean Spearman Correlation: 0.19109111042476218\n",
      "Best Params: {'depth': 6, 'learning_rate': 0.01, 'iterations': 200, 'l2_leaf_reg': 3}, Best Mean Spearman Correlation: 0.248288950880117\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'TARGET' is the name of your target variable in each dataset\n",
    "print(f\"Training CatBoost model...\")\n",
    "X = df_reduced.drop('TARGET', axis=1)\n",
    "y = df_reduced['TARGET'].rank()\n",
    "best_params = train_and_evaluate_catboost(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x296d0147890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain with best params on whole dataset\n",
    "final_model = CatBoostRegressor(silent=True, **best_params)\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = pd.read_csv('../data/raw/X_test_final.csv')\n",
    "df_test = feature_engineering(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_reduced = df_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_model.predict(df_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_submission = X_test_final[['ID']].copy()\n",
    "Y_test_submission[\"TARGET\"] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_submission.to_csv('submission_catboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e98505b2ea4c5ad54dad79b106a9e9e74f288112ea588ce88c6ce949430e0824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
